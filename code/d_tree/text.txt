One of my colleagues recently asked whether there were any adversarial examples (AEs) against gradientless models like decision trees. It's a good question: after all, most AE generation technqiues are based on some sort of gradient-based optimization of the model's input. In the absence of gradients, the problem of fooling a model turns into an algorithmic optimization problem instead of a numerical one, and this is arguably more relatable to a computer programmer who isn't much of a math whiz.


Recently, one of my colleagues asked me if there were any adversarial examples (AEs) against gradientless models such as decision trees. It's a good question: after all, many AE generation techniques rely on gradient-based optimizations of the model's inputs. In the absence of gradients, attacking these types of models becomes an algorithmic optimization challenge rather than a numerical one. This may be easier for programmers without an advanced mathematics background to grok.

TLDR;
Making an AE for a decision tree involves finding the shortest path between two leaf nodes, pruning it, and changing the features 

We'll choose decision trees as they're quite easy to interpret and easy to implement using sklearn. Let's start by fitting some toy data with 4 features f0, f1, f2, f3 to 3 classes c0, c1, c2 and visualize how it makes inferences. Our goal would be to perturb a sample just enough so that it gets misclassified.

Recall that decision trees are simply binary trees whose nodes split according to the value of an input feature. For any input, we traverse the tree until we reach a leaf node which tells us the predicted class of the input. For example, consider the following input: [.9, .2, .5, .3]. Starting from the root node, the following splits are traversed until we reach the purple leaf node at the bottom corresponding to the class c2: f2 > .45, f1 > 182, f0 <= .97, f2 <= .882, f2 <= .586, f3 <= .342. Fortunately, sklearn's documentation is really good so it's easy to unpack a decision tree into a binary tree and trace the path taken by a decision tree's forward pass.

Our goal is to make a slight perturbation to this input's features to get it "misclassified" (or at least, put in a different class). Getting it to be in class c0 is actually straightforward: simply changing f3 to be slightly greater than .342 would change the last split to take the path towards c0 instead of c2. Thus, [.9, .2, .5, .342 + 1e-5] is our adversarial example.

It's not always this easy, though. What if our target class was c1? Again, we need to change only one feature, in this case, f2 to be greater than .882, to change the predicted class to c1. How did we know that it was f2 that needed to be changed? Because f2 lies on the shortest path between our original class (c2) leaf node and target class leaf node (c0). This path is [f3 <= .342, f2 <= .586, f2 <= .882]. Note that, we do not actually need to change the nodes leading up to the highest node in our shortest path. The highest node in our path is f2 <= .882, and the nodes leading up to it are f3 <= .342 and f2 <= .586. This is because the tree makes inferences starting from the root node f2 <= .45, and the path leading to the leaf node c1 won't ever need to pass through f3 <= .342 and f2 <= .586 anyways.

In short, to change the label of a sample, we should find the shortest path between the original class's leaf node and the target classes's lead node, prune the nodes in this path leading up to the highest node, and change the remaining features. We can find the shortest path using a Breadth-First Search, using the keywords 'left' and 'right' to denote directions to take when traversing. We'll need to track the highest node as well, so we'll mark it using the keyword 'parent' during our BFS. Finally, once we have our pruned path, we change each feature by either adding or subtracting a small value (1e-3 here) depending on whethere the direction is 'left' or 'right'.

Are these AEs? Not necessarily. These are the smallest perturbations needed to change the label of a sample, but if they're not imperceptible to humans, they aren't AEs. To see how the results look on real data, let's fit the tree on MNIST and create some AEs for the digit 0.

They still look like a zeros to me, so they're definitely AEs. Note that we only needed to change about 2 pixels on average to change the label, so this shows how brittle/overfit the decision tree is, despite it having a test accuracy of 88\%.

We can see why only 2 out of 768 pixels needed to be modified by visualizing the shortest path traversed for an example. Note that in the path between the orginal class's leaf node 3354 and the target class's leaf node 3439, only three features actually needed to be changed because there's a very short path of three nodes from the highest node 3213 to the leaf node 3439. In other words, our tree has a high balance factor, making AE generation easy. It appears that minimizing the balance factor of the tree while fitting it may improve its generalization, and this is something worth researching.

What about ensembles? For ensembles of decision trees, the results can get quite hairy. Recall that ensembles make predictions by taking the majority vote amongst the predictions of each of its constituent trees. For each tree, we'd have a small proportion of features to change, and as the number of trees increase, the total number of features to change add up (depending on the diversity of the trees or, equivalently, the intersection of features to change for each tree).

Here's a test fitting 100 trees to MNIST. For each tree, we can formulate the features to change and the values they need to be changed to as a constraint. We can then collect the 100 constraints, one for each tree, and solve for the constraints using a solver like Z3.

Note that this is a greedy approach - we selected the features as per the shortest path for each tree and calculated the intersection of features for all trees - so the results aren't that great. It's possible that there exists a smaller subset of features to change, but this would mean that we'd need to look at each possible path (and not just the shortest path) for each tree. Perhaps finding intersections over the top-k shortest paths for each tree might be computationally feasible?

Adversarial examples vs counterfactual explanations. A prominent difference in the AEs generated for decision trees and the AEs generated for gradient-based models is the sparsity: For trees, only a small proportion of features/pixels needed to be changed while for gradient-based models, all the pixels needed to be changed. Consequently, for trees, each of the few pixels changed needed to be changed be a large value, while for gradient-based models, all the pixels needed to be changed by a very imperceptible value.

The AEs generated for trees seem a bit like counterfactual explanations (CEs). In CEs, we look to make changes to the best possible features to get a sample misclassified. By "best features" here, we mean the features that make sense to a human (as opposed to the human-imperceptible changes required for an AE). For example, a CE for the digit 1 might add a C-shaped curve to the top of the 1 so that it gets classified as a 9 and at looks like a 9 to a human at the same time. Note the pixels changes are sparse much like AEs for trees and unlike AEs for gradient-based models. Unfortunately, for deep trees involving high-dimensional data like images, the perturbations are __too sparse__, rendering it imperceptible to humans. However, for lower-dimensional tabular data, perhaps an AE is a CE? Here's a quick test on a loan default dataset where we ask the question "what feature, if changed for an applicant whose loan was denied, would have got his loan approved?". Does the AE make sense? Look at the results and decide for yourself.
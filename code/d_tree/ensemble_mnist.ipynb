{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4fa7c86e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "from sklearn import tree\n",
    "import torchvision.datasets as dsets\n",
    "from torchvision import transforms\n",
    "import torch\n",
    "\n",
    "from util import bfs, traverse_to_node, unpack_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0e60cc8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(clfs, x):\n",
    "    preds = []\n",
    "    for clf in clfs:\n",
    "        preds.append(clf.predict(x)[0])\n",
    "    return max(set(preds), key=preds.count)\n",
    "\n",
    "\n",
    "def fit_ensemble(X, y, n_clfs=5):\n",
    "    clfs = []\n",
    "    for i in range(n_clfs):\n",
    "        print(f'Training clf: {i}')\n",
    "        ix = np.random.choice(range(X.shape[0]), X.shape[0] // 5)\n",
    "        X_ = X[ix]\n",
    "        y_ = y[ix]\n",
    "\n",
    "        clf = DecisionTreeClassifier(random_state=i)\n",
    "        model = clf.fit(X_, y_)\n",
    "\n",
    "        clfs.append(clf)\n",
    "    return clfs\n",
    "\n",
    "\n",
    "def get_constraints(clf, sample, target_cls=0):\n",
    "    root, feature, threshold = unpack_tree(clf)\n",
    "    \n",
    "    # Get the leaf node\n",
    "    node, _ = traverse_to_node(root, sample, feature, threshold)\n",
    "\n",
    "    # Get the shortest path from the leaf node to the target class's leaf node\n",
    "    path = bfs(node, target_cls=target_cls)\n",
    "    # Index of the top-most parent\n",
    "    ix = path[::-1].index('parent')\n",
    "\n",
    "    # Travel up to the top-most parent\n",
    "    for dir in path[:-ix]:\n",
    "        node = node.parent\n",
    "\n",
    "    constraints = []\n",
    "    # Don't change each feature in the remaining path,\n",
    "    # add it to constraints\n",
    "    for dir in path[-ix:]:\n",
    "        thresh = threshold[node.id]\n",
    "        feat = feature[node.id]\n",
    "\n",
    "        if dir == 'left':\n",
    "            constraints.append((f'f{feat}', '<=', thresh))\n",
    "            node = node.left\n",
    "        else:\n",
    "            constraints.append((f'f{feat}', '>', thresh))\n",
    "            node = node.right\n",
    "\n",
    "    return constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4401e6e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training clf: 0\n",
      "Training clf: 1\n",
      "Training clf: 2\n",
      "Training clf: 3\n",
      "Training clf: 4\n",
      "Training clf: 5\n",
      "Training clf: 6\n",
      "Training clf: 7\n",
      "Training clf: 8\n",
      "Training clf: 9\n",
      "Training clf: 10\n",
      "Training clf: 11\n",
      "Training clf: 12\n",
      "Training clf: 13\n",
      "Training clf: 14\n",
      "Training clf: 15\n",
      "Training clf: 16\n",
      "Training clf: 17\n",
      "Training clf: 18\n",
      "Training clf: 19\n",
      "Training clf: 20\n",
      "Training clf: 21\n",
      "Training clf: 22\n",
      "Training clf: 23\n",
      "Training clf: 24\n",
      "Training clf: 25\n",
      "Training clf: 26\n",
      "Training clf: 27\n",
      "Training clf: 28\n",
      "Training clf: 29\n",
      "Training clf: 30\n",
      "Training clf: 31\n",
      "Training clf: 32\n",
      "Training clf: 33\n",
      "Training clf: 34\n",
      "Training clf: 35\n",
      "Training clf: 36\n",
      "Training clf: 37\n",
      "Training clf: 38\n",
      "Training clf: 39\n",
      "Training clf: 40\n",
      "Training clf: 41\n",
      "Training clf: 42\n",
      "Training clf: 43\n",
      "Training clf: 44\n",
      "Training clf: 45\n",
      "Training clf: 46\n",
      "Training clf: 47\n",
      "Training clf: 48\n",
      "Training clf: 49\n",
      "Training clf: 50\n",
      "Training clf: 51\n",
      "Training clf: 52\n",
      "Training clf: 53\n",
      "Training clf: 54\n",
      "Training clf: 55\n",
      "Training clf: 56\n",
      "Training clf: 57\n",
      "Training clf: 58\n",
      "Training clf: 59\n",
      "Training clf: 60\n",
      "Training clf: 61\n",
      "Training clf: 62\n",
      "Training clf: 63\n",
      "Training clf: 64\n",
      "Training clf: 65\n",
      "Training clf: 66\n",
      "Training clf: 67\n",
      "Training clf: 68\n",
      "Training clf: 69\n",
      "Training clf: 70\n",
      "Training clf: 71\n",
      "Training clf: 72\n",
      "Training clf: 73\n",
      "Training clf: 74\n",
      "Training clf: 75\n",
      "Training clf: 76\n",
      "Training clf: 77\n",
      "Training clf: 78\n",
      "Training clf: 79\n",
      "Training clf: 80\n",
      "Training clf: 81\n",
      "Training clf: 82\n",
      "Training clf: 83\n",
      "Training clf: 84\n",
      "Training clf: 85\n",
      "Training clf: 86\n",
      "Training clf: 87\n",
      "Training clf: 88\n",
      "Training clf: 89\n",
      "Training clf: 90\n",
      "Training clf: 91\n",
      "Training clf: 92\n",
      "Training clf: 93\n",
      "Training clf: 94\n",
      "Training clf: 95\n",
      "Training clf: 96\n",
      "Training clf: 97\n",
      "Training clf: 98\n",
      "Training clf: 99\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "\n",
    "# Prepare the data\n",
    "num_classes = 10\n",
    "\n",
    "train_data = dsets.MNIST(root=\"./data\", train=True, transform=transforms.ToTensor(), download=True)\n",
    "test_data = dsets.MNIST(root=\"./data\", train=False, transform=transforms.ToTensor(), download=True)\n",
    "\n",
    "X, y = [], []\n",
    "X_test, y_test = [], []\n",
    "\n",
    "for row in train_data:\n",
    "    X.append(row[0])\n",
    "    y.append(row[1])\n",
    "\n",
    "for row in test_data:\n",
    "    X_test.append(row[0])\n",
    "    y_test.append(row[1])\n",
    "\n",
    "X = torch.vstack(X)\n",
    "X = X.reshape(X.shape[0], -1).numpy()\n",
    "y = np.array(y)\n",
    "X_test = torch.vstack(X_test)\n",
    "X_test = X_test.reshape(X_test.shape[0], -1).numpy()\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "clfs = fit_ensemble(X, y, n_clfs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3fdee29b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier 0: [('f408', '>', 0.019607843831181526), ('f386', '<=', 0.02549019642174244), ('f378', '>', 0.029411765281111002), ('f323', '>', 0.9117647111415863), ('f263', '<=', 0.18627451360225677), ('f435', '>', 0.9901960790157318)]\n",
      "Classifier 1: [('f434', '>', 0.013725490774959326), ('f375', '<=', 0.0019607844296842813), ('f550', '<=', 0.0058823530562222), ('f234', '>', 0.007843137718737125), ('f548', '>', 0.6745098233222961), ('f543', '<=', 0.0117647061124444), ('f661', '>', 0.35098040103912354)]\n",
      "Classifier 2: [('f483', '<=', 0.2666666805744171), ('f350', '>', 0.03333333507180214), ('f486', '>', 0.19607843458652496), ('f540', '<=', 0.13921568915247917), ('f653', '<=', 0.13137255050241947), ('f611', '>', 0.0117647061124444), ('f180', '<=', 0.0784313753247261)]\n",
      "Classifier 3: [('f434', '>', 0.0019607844296842813), ('f375', '<=', 0.0019607844296842813), ('f206', '<=', 0.003921568859368563), ('f522', '>', 0.01764705963432789), ('f372', '<=', 0.045098040252923965), ('f632', '>', 0.3176470696926117), ('f575', '>', 0.794117659330368)]\n",
      "Classifier 4: [('f455', '<=', 0.013725490774959326), ('f176', '<=', 0.09607843682169914), ('f243', '<=', 0.01960784406401217), ('f323', '<=', 0.04509804071858525), ('f544', '<=', 0.1941176513209939), ('f433', '>', 0.0019607844296842813), ('f318', '<=', 0.26274511218070984)]\n"
     ]
    }
   ],
   "source": [
    "sample = X[1]\n",
    "constraints = []\n",
    "target_cls = 1\n",
    "\n",
    "for clf in clfs:\n",
    "    root, feature, threshold = unpack_tree(clf)\n",
    "    actual_label = clf.predict([sample])[0]\n",
    "\n",
    "    if actual_label == target_cls:\n",
    "        continue\n",
    "    constraints_ = get_constraints(\n",
    "        clf,\n",
    "        sample,\n",
    "        target_cls=target_cls\n",
    "    )\n",
    "\n",
    "    constraints.append(constraints_)\n",
    "\n",
    "for i, constraint in enumerate(constraints[:5]):\n",
    "    print(f\"Classifier {i}: {constraint}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ecaef8e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of pixels changed: 184\n",
      "Predicted class: 1\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from z3 import Real, Solver, sat\n",
    "\n",
    "vars = {}\n",
    "s = Solver()\n",
    "\n",
    "# Greedy\n",
    "for constraint_ in constraints:\n",
    "    prev_constraints = s.assertions()\n",
    "    for constraint in constraint_:\n",
    "        feat, sign, thresh = constraint\n",
    "        if feat not in vars:\n",
    "            vars[feat] = Real(feat)\n",
    "        if sign == '>':\n",
    "            s.add(vars[feat] > thresh)\n",
    "        else:\n",
    "            s.add(vars[feat] <= thresh)\n",
    "        # If we reach an unsolvable constraint, skip it,\n",
    "        # and recreate the solver with the previous constriaints\n",
    "        if s.check() != sat:\n",
    "            s = Solver()\n",
    "            for prev_constraint in prev_constraints:\n",
    "                s.add(prev_constraint)\n",
    "            break\n",
    "            \n",
    "s.check()\n",
    "model = s.model()\n",
    "adv_sample = sample.copy()\n",
    "n_pixels_changed = 0\n",
    "\n",
    "for feat in vars:\n",
    "    val = model[vars[feat]]\n",
    "    if val is None:\n",
    "        continue\n",
    "    n_pixels_changed += 1\n",
    "    val = val.as_fraction()\n",
    "    val = float(val.numerator) / float(val.denominator)\n",
    "    adv_sample[int(feat[1:])] = val\n",
    "\n",
    "print(f\"Number of pixels changed: {n_pixels_changed}\")\n",
    "print(f\"Predicted class: {clf.predict([adv_sample])[0]}\")\n",
    "fig, ax = plt.subplots(nrows=1, ncols=2)\n",
    "ax[0].imshow(sample.reshape(28, 28))\n",
    "ax[1].imshow(adv_sample.reshape(28, 28))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdbefe01",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
